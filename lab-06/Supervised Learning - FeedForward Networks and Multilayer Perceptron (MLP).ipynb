{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23fd7fca",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\"> </hr>\n",
    "<img src=\"https://mma.prnewswire.com/media/1095203/East_Tennessee_State_University_Logo.jpg?p=facebook\" width=200 height=200 />\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <h1 style=\"text-align: center\">CSCI 5270 - Machine Learning</h1>\n",
    "</div>\n",
    "\n",
    "### <center>Supervised Learning - FeedForward Networks and Multilayer Perceptron (MLP) </center>\n",
    "\n",
    "<center>Dr. Ahmad Al-Doulat </center>\n",
    "<center>Department of Computing </center>\n",
    "<center>East Tennessee State University</center>\n",
    "\n",
    "<hr style=\"border:2px solid lightblue\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c3c529",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h2 style=\"text-align: left\">Regression with Multilayer Perceptron Using sklearn</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3c357c",
   "metadata": {},
   "source": [
    "#### Dataset:\n",
    "We'll use the Housing dataset, which contains information about housing. The task is to predict the median value of owner-occupied homes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756e896f",
   "metadata": {},
   "source": [
    "#### Step 1: Data Loading and Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0173e4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('housing.csv')\n",
    "\n",
    "# Split the data into features and target\n",
    "X = data.drop('medv', axis=1)\n",
    "y = data['medv']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b9127a",
   "metadata": {},
   "source": [
    "#### Step 2: Model Building and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7d33c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aldou\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(activation=&#x27;tanh&#x27;, hidden_layer_sizes=(100, 50), max_iter=2000,\n",
       "             random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(activation=&#x27;tanh&#x27;, hidden_layer_sizes=(100, 50), max_iter=2000,\n",
       "             random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(activation='tanh', hidden_layer_sizes=(100, 50), max_iter=2000,\n",
       "             random_state=42)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Create MLP Regressor\n",
    "mlp_regressor = MLPRegressor(hidden_layer_sizes=(100, 50),\n",
    "                             activation='tanh',\n",
    "                             solver='adam',\n",
    "                             max_iter=2000,\n",
    "                             alpha=0.0001,\n",
    "                             random_state=42)\n",
    "\n",
    "# Train the model\n",
    "mlp_regressor.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d220bd6d",
   "metadata": {},
   "source": [
    "#### Step 3: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0ffa78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 23.694546443841087\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Predictions\n",
    "y_pred = mlp_regressor.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76369bd5",
   "metadata": {},
   "source": [
    "#### Step 4: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66b0659",
   "metadata": {},
   "source": [
    "#### Hyperparameters:\n",
    "\n",
    "1. `'hidden_layer_sizes'`: This parameter specifies the number of neurons in each hidden layer of the Multi-layer Perceptron (MLP) model. It is a list of tuples, where each tuple represents a different configuration of hidden layer sizes. For example,\n",
    "\n",
    "    - `(50,)` indicates one hidden layer with 50 neurons, \n",
    "    - `(100,)` indicates one hidden layer with 100 neurons, \n",
    "    - `(50, 50)` indicates two hidden layers with 50 neurons each, and \n",
    "    - `(100, 50)` indicates two hidden layers with 100 and 50 neurons, respectively.\n",
    "\n",
    "2. `'activation'`: This parameter specifies the activation function for the neurons in the MLP model. It is a list containing strings representing different activation functions. In this case, it includes `'relu'` (Rectified Linear Unit) and `'tanh'` (Hyperbolic Tangent). Some common activation functions used in neural networks along with their descriptions:\n",
    "\n",
    "    1.1. **ReLU (Rectified Linear Unit)**:\n",
    "   - Formula: $f(x) = \\max(0, x)$\n",
    "   - Description: ReLU is one of the most widely used activation functions. It introduces non-linearity to the model by outputting the input directly if it is positive, and zero otherwise. ReLU is computationally efficient and helps mitigate the vanishing gradient problem.\n",
    "\n",
    "    1.2. **Tanh (Hyperbolic Tangent)**:\n",
    "   - Formula: $f(x) = \\frac{{e^x - e^{-x}}}{{e^x + e^{-x}}}$\n",
    "   - Description: Tanh is another popular activation function. It squashes the input values between -1 and 1, making it zero-centered. Tanh is often used in hidden layers of neural networks, especially when the data is normalized, as it helps with training stability.\n",
    "\n",
    "    1.3. **Sigmoid (Logistic)**:\n",
    "   - Formula: $f(x) = \\frac{1}{{1 + e^{-x}}}$\n",
    "   - Description: Sigmoid function is commonly used in binary classification problems. It squashes the input values between 0 and 1, interpreting them as probabilities. However, it suffers from the vanishing gradient problem, especially during backpropagation.\n",
    "\n",
    "    1.4. **Softmax**:\n",
    "   - Formula: $f(x_i) = \\frac{{e^{x_i}}}{{\\sum_{j} e^{x_j}}}$\n",
    "   - Description: Softmax is often used in the output layer of neural networks for multi-class classification problems. It normalizes the output values into a probability distribution, where each output represents the probability of a class. Softmax ensures that the sum of all probabilities is equal to 1.\n",
    "\n",
    "    1.5. **Leaky ReLU**:\n",
    "   - Formula: $f(x) = \\begin{cases} x & \\text{if } x > 0 \\\\ \\text{constant} \\times x & \\text{otherwise} \\end{cases}$\n",
    "   - Description: Leaky ReLU is a variant of ReLU that addresses the \"dying ReLU\" problem. It allows a small, non-zero gradient when the input is negative, preventing neurons from becoming inactive during training.\n",
    "\n",
    "These are some of the most commonly used activation functions in neural networks, each with its own characteristics and suitability for different types of problems and architectures.\n",
    "\n",
    "3. `'solver'`: This parameter specifies the optimization algorithm used to update the weights of the neural network during training. It is a list containing strings representing different solvers. In this case, it includes `'adam'` (adaptive moment estimation) and `'sgd'` (stochastic gradient descent).\n",
    "\n",
    "    3.1. **Adam (Adaptive Moment Estimation)**:\n",
    "    - Description: Adam is an adaptive learning rate optimization algorithm that combines the advantages of two other extensions of stochastic gradient descent, namely Adagrad and RMSprop. It maintains adaptive learning rates for each parameter and computes the first and second moments of the gradients to adaptively adjust the learning rates.\n",
    "\n",
    "    3.2. **SGD (Stochastic Gradient Descent)**:\n",
    "    - Description: Stochastic Gradient Descent is a fundamental optimization algorithm used for training neural networks. It updates the model parameters by computing the gradient of the loss function with respect to the parameters for each training example and adjusting the parameters in the opposite direction of the gradient. It operates on batches of training data, and the learning rate determines the step size in the parameter space.\n",
    "\n",
    "4. `'alpha'`: This parameter represents the L2 penalty (regularization term) parameter. It is a list containing float values representing different regularization strengths. In this case, it includes 0.0001, 0.001, and 0.01. Regularization is a technique used to prevent overfitting in machine learning models. Regularization techniques impose additional constraints on the model, discouraging overly complex solutions that may lead to overfitting.\n",
    "\n",
    "These parameters and their corresponding values define a grid of hyperparameters that will be searched exhaustively by `GridSearchCV` to find the best combination of hyperparameters for the MLPRegressor model. The best combination will be determined based on the performance metric (mean squared error in this case) evaluated through cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6492c6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (100,), 'solver': 'sgd'}\n",
      "Best Model Mean Squared Error: 12.956837798198732\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(MLPRegressor(max_iter=2000, random_state=42), param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate model with best parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Best Model Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bd9093",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h2 style=\"text-align: left\">Classification with Multilayer Perceptron Using sklearn</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc606b",
   "metadata": {},
   "source": [
    "#### Dataset:\n",
    "We'll use the Iris dataset available in scikit-learn, which contains information about iris flowers and the task is to classify them into three species."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2386af50",
   "metadata": {},
   "source": [
    "#### Step 1: Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72c5fbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('housing.csv')\n",
    "\n",
    "# Split the data into features and target\n",
    "X = data.drop('medv', axis=1)\n",
    "y = data['medv']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0efb2bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4b629a",
   "metadata": {},
   "source": [
    "#### Step 2: Model Building and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5808e45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create MLP Classifier\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(100, 50),\n",
    "                               activation='relu',\n",
    "                               solver='adam',\n",
    "                               max_iter=500,\n",
    "                               random_state=42)\n",
    "\n",
    "# Train the model\n",
    "mlp_classifier.fit(X_train_scaled, y_train_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a08992",
   "metadata": {},
   "source": [
    "#### Step 3: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "158ac493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predictions\n",
    "y_pred = mlp_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b2aa75",
   "metadata": {},
   "source": [
    "#### Step 4: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251d6f3a",
   "metadata": {},
   "source": [
    "`np.logspace(-4, 0, 5)`: This part of the code uses NumPy's `logspace` function to generate an array of values for alpha. Here's what each argument means:\n",
    "\n",
    "   - `-4`: This is the start exponent of the sequence. In this case, it's -4, so the smallest value generated will be $10^{-4}$.\n",
    "   \n",
    "   - `0`: This is the stop exponent of the sequence. It's 0, so the largest value generated will be $10^0 = 1$.\n",
    "   \n",
    "   - `5`: This is the number of values to generate between the start and stop exponents, inclusive. So, in this case, it will generate 5 values spaced evenly on a logarithmic scale between $10^{-4}$ and $10^0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c64785a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n",
      "0.001\n",
      "0.01\n",
      "0.1\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for item in np.logspace(-4, 0, 5):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bde9f0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'solver': 'sgd', 'hidden_layer_sizes': (100, 50), 'alpha': 0.01, 'activation': 'relu'}\n",
      "Best Model Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Define parameter distribution\n",
    "param_dist = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': np.logspace(-4, 0, 5),\n",
    "}\n",
    "\n",
    "# Perform Randomized Search\n",
    "random_search = RandomizedSearchCV(MLPClassifier(max_iter=2000, random_state=42), param_dist, cv=5, n_iter=10)\n",
    "random_search.fit(X_train_scaled, y_train_encoded)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "\n",
    "# Evaluate model with best parameters\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "print(\"Best Model Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211beb6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
