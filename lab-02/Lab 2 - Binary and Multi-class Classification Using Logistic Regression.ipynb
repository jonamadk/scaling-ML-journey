{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87363b4b",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\"> </hr>\n",
    "<img src=\"https://mma.prnewswire.com/media/1095203/East_Tennessee_State_University_Logo.jpg?p=facebook\" width=200 height=200 />\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <h1 style=\"text-align: center\">CSCI 5270 - Machine Learning</h1>\n",
    "</div>\n",
    "\n",
    "# <center>Lab 2 - Binary and Multi-class Classification Using Logistic Regression</center>\n",
    "\n",
    "**<center>Dr. Ahmad Al-Doulat </center>**\n",
    "<center>Department of Computing </center>\n",
    "<center>East Tennessee State University</center>\n",
    "\n",
    "<hr style=\"border:2px solid lightblue\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f647de7f",
   "metadata": {},
   "source": [
    "**In this assignment, you'll get to practice the concepts and skills covered in the course so far. The main objective of this assignment is to implement, test and evaluate two logistic regression models- Binary and Multi-class Classification Using Logistic Regression.**\n",
    "\n",
    "\n",
    "\n",
    "**Guidelines**\n",
    "* Download `weatherAUS.csv` and `penguins.csv` files from D2L. \n",
    "* Make sure to run all the code cells, otherwise you may get errors like `NameError` for undefined variables.\n",
    "* Do not change variable names, delete cells or disturb other existing code. It may cause problems during evaluation.\n",
    "* In some cases, you may need to add some code cells or new statements before or after the line of code containing the `???`.\n",
    "* Use markdown cells to write your discussions and reflections. \n",
    "\n",
    "**Procedure**\n",
    "* Save your work as `IPYNB` file and submit to D2L `Lab 2 - Binary and Multi-class Classification Using Logistic Regression (Dropbox)` by the due date.\n",
    "* As you go through this notebook, you will find the symbol `???` in certain places. To complete this assignment, you must replace all the `???` with appropriate values, expressions or statements to ensure that the notebook runs properly end-to-end.\n",
    "* Include your response for `Part 1` and `Part 2` in this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021e19a6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "# Part 1: Activity \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6a1547",
   "metadata": {},
   "source": [
    "# Question 1: Binary Classification Using Logistic Regression\n",
    "<hr style=\"border:1px solid orange\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fee93f4",
   "metadata": {},
   "source": [
    "#### Read the content of the `weatherAUS.csv` file into a dataset and perform the following:\n",
    "\n",
    "> **Q1.1.** Preprocess and clean the dataset (**Note:** Make sure to document your preprocessing step): This step should include the following:\n",
    "\n",
    "    - Dealing with the missing data\n",
    "    - Dealing with the irregular data (outliers)\n",
    "    - Dealing with the unnecessary data\n",
    "    - Dealing with the inconsistent data\n",
    "    - Encoding categorical data \n",
    "\n",
    "> **Q1.2.** Visualize the dataset\n",
    "\n",
    "> **Q1.3.** Discuss the preliminary observations about the dataset. You may base your discussion on your visualizations, measures of central tendency, and measures of variability \n",
    "\n",
    "> **Q1.4.** Build a classification model using Logistic Regression to predict the target variable `RainTomorrow` from the dataset.\n",
    "\n",
    "> **Q1.5.** Evaluate and discuss the model performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9e2eaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e35af07a-fa88-4c14-8f15-81ab22cd6d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RISK_MM</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/18/2009</td>\n",
       "      <td>Hobart</td>\n",
       "      <td>5.1</td>\n",
       "      <td>14.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>8.9</td>\n",
       "      <td>NW</td>\n",
       "      <td>30.0</td>\n",
       "      <td>WSW</td>\n",
       "      <td>...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1023.1</td>\n",
       "      <td>1022.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>13.3</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7/3/2009</td>\n",
       "      <td>Launceston</td>\n",
       "      <td>1.1</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SSW</td>\n",
       "      <td>50.0</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1001.5</td>\n",
       "      <td>1002.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.3</td>\n",
       "      <td>13.7</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2/18/2010</td>\n",
       "      <td>Williamtown</td>\n",
       "      <td>19.7</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7.2</td>\n",
       "      <td>SSE</td>\n",
       "      <td>41.0</td>\n",
       "      <td>SSE</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1020.9</td>\n",
       "      <td>1021.9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>No</td>\n",
       "      <td>0.2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3/4/2010</td>\n",
       "      <td>PerthAirport</td>\n",
       "      <td>16.6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>SW</td>\n",
       "      <td>54.0</td>\n",
       "      <td>SSE</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1018.3</td>\n",
       "      <td>1014.9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.1</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9/9/2010</td>\n",
       "      <td>GoldCoast</td>\n",
       "      <td>14.6</td>\n",
       "      <td>25.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NNW</td>\n",
       "      <td>43.0</td>\n",
       "      <td>WNW</td>\n",
       "      <td>...</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1020.3</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.2</td>\n",
       "      <td>22.6</td>\n",
       "      <td>No</td>\n",
       "      <td>0.4</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date      Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
       "0  5/18/2009        Hobart      5.1     14.3       0.0          1.8       8.9   \n",
       "1   7/3/2009    Launceston      1.1     14.5       0.4          NaN       NaN   \n",
       "2  2/18/2010   Williamtown     19.7     26.2       0.0          7.2       7.2   \n",
       "3   3/4/2010  PerthAirport     16.6     28.0       0.0          9.0      11.3   \n",
       "4   9/9/2010     GoldCoast     14.6     25.3       0.0          NaN       NaN   \n",
       "\n",
       "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity3pm  Pressure9am  \\\n",
       "0          NW           30.0        WSW  ...        47.0       1023.1   \n",
       "1         SSW           50.0          E  ...        46.0       1001.5   \n",
       "2         SSE           41.0        SSE  ...        50.0       1020.9   \n",
       "3          SW           54.0        SSE  ...        41.0       1018.3   \n",
       "4         NNW           43.0        WNW  ...        67.0       1020.3   \n",
       "\n",
       "   Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  RISK_MM  \\\n",
       "0       1022.2       1.0       1.0      9.1     13.3         No      0.0   \n",
       "1       1002.4       NaN       NaN      1.3     13.7         No      0.0   \n",
       "2       1021.9       6.0       4.0     22.7     24.4         No      0.2   \n",
       "3       1014.9       6.0       1.0     20.0     26.1         No      0.0   \n",
       "4       1015.0       NaN       NaN     22.2     22.6         No      0.4   \n",
       "\n",
       "   RainTomorrow  \n",
       "0            No  \n",
       "1            No  \n",
       "2            No  \n",
       "3            No  \n",
       "4            No  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weatherAUS_df = pd.read_csv('weatherAUS.csv')\n",
    "weatherAUS_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "693dc049-6e19-4ddb-81af-6eb289ad1582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36881 entries, 0 to 36880\n",
      "Data columns (total 24 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Date           36881 non-null  object \n",
      " 1   Location       36881 non-null  object \n",
      " 2   MinTemp        36543 non-null  float64\n",
      " 3   MaxTemp        36639 non-null  float64\n",
      " 4   Rainfall       36255 non-null  float64\n",
      " 5   Evaporation    24035 non-null  float64\n",
      " 6   Sunshine       23317 non-null  float64\n",
      " 7   WindGustDir    33513 non-null  object \n",
      " 8   WindGustSpeed  33520 non-null  float64\n",
      " 9   WindDir9am     34072 non-null  object \n",
      " 10  WindDir3pm     35919 non-null  object \n",
      " 11  WindSpeed9am   36219 non-null  float64\n",
      " 12  WindSpeed3pm   36235 non-null  float64\n",
      " 13  Humidity9am    36311 non-null  float64\n",
      " 14  Humidity3pm    36370 non-null  float64\n",
      " 15  Pressure9am    33309 non-null  float64\n",
      " 16  Pressure3pm    33329 non-null  float64\n",
      " 17  Cloud9am       24381 non-null  float64\n",
      " 18  Cloud3pm       23899 non-null  float64\n",
      " 19  Temp9am        36394 non-null  float64\n",
      " 20  Temp3pm        36437 non-null  float64\n",
      " 21  RainToday      36255 non-null  object \n",
      " 22  RISK_MM        36261 non-null  float64\n",
      " 23  RainTomorrow   36261 non-null  object \n",
      "dtypes: float64(17), object(7)\n",
      "memory usage: 6.8+ MB\n"
     ]
    }
   ],
   "source": [
    "weatherAUS_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4be6118c-6412-4c47-be6b-b80501d94613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RISK_MM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36543.000000</td>\n",
       "      <td>36639.000000</td>\n",
       "      <td>36255.000000</td>\n",
       "      <td>24035.000000</td>\n",
       "      <td>23317.000000</td>\n",
       "      <td>33520.000000</td>\n",
       "      <td>36219.000000</td>\n",
       "      <td>36235.000000</td>\n",
       "      <td>36311.000000</td>\n",
       "      <td>36370.000000</td>\n",
       "      <td>33309.000000</td>\n",
       "      <td>33329.000000</td>\n",
       "      <td>24381.000000</td>\n",
       "      <td>23899.000000</td>\n",
       "      <td>36394.000000</td>\n",
       "      <td>36437.000000</td>\n",
       "      <td>36261.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.235966</td>\n",
       "      <td>22.939491</td>\n",
       "      <td>2.554823</td>\n",
       "      <td>5.189544</td>\n",
       "      <td>7.544688</td>\n",
       "      <td>40.390573</td>\n",
       "      <td>14.217427</td>\n",
       "      <td>18.874928</td>\n",
       "      <td>69.146953</td>\n",
       "      <td>52.307369</td>\n",
       "      <td>1017.283152</td>\n",
       "      <td>1014.967769</td>\n",
       "      <td>4.331488</td>\n",
       "      <td>4.462321</td>\n",
       "      <td>16.905688</td>\n",
       "      <td>21.485808</td>\n",
       "      <td>2.554748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.389832</td>\n",
       "      <td>6.988266</td>\n",
       "      <td>9.081329</td>\n",
       "      <td>3.765427</td>\n",
       "      <td>3.833809</td>\n",
       "      <td>13.550613</td>\n",
       "      <td>8.997003</td>\n",
       "      <td>8.791849</td>\n",
       "      <td>18.300754</td>\n",
       "      <td>20.317082</td>\n",
       "      <td>7.177877</td>\n",
       "      <td>7.077594</td>\n",
       "      <td>2.848750</td>\n",
       "      <td>2.663067</td>\n",
       "      <td>6.428328</td>\n",
       "      <td>6.820848</td>\n",
       "      <td>8.940267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-8.500000</td>\n",
       "      <td>-3.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>982.900000</td>\n",
       "      <td>980.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.900000</td>\n",
       "      <td>-5.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.600000</td>\n",
       "      <td>17.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1012.500000</td>\n",
       "      <td>1010.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.300000</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.100000</td>\n",
       "      <td>22.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>1017.300000</td>\n",
       "      <td>1015.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>16.600000</td>\n",
       "      <td>20.900000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>27.900000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1022.200000</td>\n",
       "      <td>1019.800000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>26.200000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.500000</td>\n",
       "      <td>48.100000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>81.200000</td>\n",
       "      <td>14.300000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1041.000000</td>\n",
       "      <td>1039.600000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>37.700000</td>\n",
       "      <td>46.100000</td>\n",
       "      <td>367.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            MinTemp       MaxTemp      Rainfall   Evaporation      Sunshine  \\\n",
       "count  36543.000000  36639.000000  36255.000000  24035.000000  23317.000000   \n",
       "mean      12.235966     22.939491      2.554823      5.189544      7.544688   \n",
       "std        6.389832      6.988266      9.081329      3.765427      3.833809   \n",
       "min       -8.500000     -3.100000      0.000000      0.000000      0.000000   \n",
       "25%        7.600000     17.800000      0.000000      2.600000      4.700000   \n",
       "50%       12.100000     22.300000      0.000000      4.600000      8.400000   \n",
       "75%       17.000000     27.900000      0.800000      7.000000     10.600000   \n",
       "max       30.500000     48.100000    371.000000     81.200000     14.300000   \n",
       "\n",
       "       WindGustSpeed  WindSpeed9am  WindSpeed3pm   Humidity9am   Humidity3pm  \\\n",
       "count   33520.000000  36219.000000  36235.000000  36311.000000  36370.000000   \n",
       "mean       40.390573     14.217427     18.874928     69.146953     52.307369   \n",
       "std        13.550613      8.997003      8.791849     18.300754     20.317082   \n",
       "min         7.000000      0.000000      0.000000      2.000000      1.000000   \n",
       "25%        31.000000      7.000000     13.000000     58.000000     38.000000   \n",
       "50%        39.000000     13.000000     19.000000     70.000000     53.000000   \n",
       "75%        48.000000     20.000000     24.000000     83.000000     66.000000   \n",
       "max       135.000000     87.000000     87.000000    100.000000    100.000000   \n",
       "\n",
       "        Pressure9am   Pressure3pm      Cloud9am      Cloud3pm       Temp9am  \\\n",
       "count  33309.000000  33329.000000  24381.000000  23899.000000  36394.000000   \n",
       "mean    1017.283152   1014.967769      4.331488      4.462321     16.905688   \n",
       "std        7.177877      7.077594      2.848750      2.663067      6.428328   \n",
       "min      982.900000    980.200000      0.000000      0.000000     -5.900000   \n",
       "25%     1012.500000   1010.100000      1.000000      2.000000     12.300000   \n",
       "50%     1017.300000   1015.000000      5.000000      5.000000     16.600000   \n",
       "75%     1022.200000   1019.800000      7.000000      7.000000     21.500000   \n",
       "max     1041.000000   1039.600000      9.000000      8.000000     37.700000   \n",
       "\n",
       "            Temp3pm       RISK_MM  \n",
       "count  36437.000000  36261.000000  \n",
       "mean      21.485808      2.554748  \n",
       "std        6.820848      8.940267  \n",
       "min       -5.100000      0.000000  \n",
       "25%       16.500000      0.000000  \n",
       "50%       20.900000      0.000000  \n",
       "75%       26.200000      0.800000  \n",
       "max       46.100000    367.600000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weatherAUS_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea32bd9-9476-451c-b423-29395d5f8cbc",
   "metadata": {},
   "source": [
    "#### **Data Pre-processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0f4846b-6b59-4b04-b283-170086e717e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                 0\n",
      "Location             0\n",
      "MinTemp            338\n",
      "MaxTemp            242\n",
      "Rainfall           626\n",
      "Evaporation      12846\n",
      "Sunshine         13564\n",
      "WindGustDir       3368\n",
      "WindGustSpeed     3361\n",
      "WindDir9am        2809\n",
      "WindDir3pm         962\n",
      "WindSpeed9am       662\n",
      "WindSpeed3pm       646\n",
      "Humidity9am        570\n",
      "Humidity3pm        511\n",
      "Pressure9am       3572\n",
      "Pressure3pm       3552\n",
      "Cloud9am         12500\n",
      "Cloud3pm         12982\n",
      "Temp9am            487\n",
      "Temp3pm            444\n",
      "RainToday          626\n",
      "RISK_MM            620\n",
      "RainTomorrow       620\n",
      "dtype: int64\n",
      "Total NA Count\t=> 75908\n"
     ]
    }
   ],
   "source": [
    "NA_val_across_columns = weatherAUS_df.isnull().sum()\n",
    "print(NA_val_across_columns)\n",
    "\n",
    "total_NA_count_across_df = NA_val_across_columns.sum()\n",
    "print(\"Total NA Count\\t=>\",total_NA_count_across_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6089d4a4-ad4c-4824-9380-f5a33d2bf578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows and keep only the last occurrence\n",
    "weatherAUS_df = weatherAUS_df.drop_duplicates(keep='last')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35f6e143-9148-4c20-8bae-e8bfd38071d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove NA values from the Target and Encode the target class values\n",
    "weatherAUS_df.dropna(subset=['RainTomorrow'], inplace=True)\n",
    "# weatherAUS_df['RainTomorrow']= weatherAUS_df['RainTomorrow'].replace({\"Yes\":1, \"No\":0}) \n",
    "# weatherAUS_df['RainTomorrow'] = weatherAUS_df['RainTomorrow'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5338b4a3-cd82-4724-9086-0f6c68c6e94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with at least one NaN value: 18883\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming weatherAUS_df is your DataFrame\n",
    "\n",
    "# Count rows with at least one NaN value\n",
    "count_na_rows = weatherAUS_df.isna().any(axis=1).sum()\n",
    "\n",
    "print(\"Number of rows with at least one NaN value:\", count_na_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce16217c-953f-45d5-b358-6bae7d20a7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Select numeric columns for normalization and imputation\n",
    "numeric_columns = weatherAUS_df.select_dtypes(include=['number'])\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Normalize the numeric columns\n",
    "normalized_data = scaler.fit_transform(numeric_columns)\n",
    "\n",
    "# Convert the normalized data back to a DataFrame\n",
    "normalized_df = pd.DataFrame(normalized_data, columns=numeric_columns.columns, index=weatherAUS_df.index)\n",
    "\n",
    "# Initialize the KNN imputer\n",
    "imputer = KNNImputer(n_neighbors=5)  # You can adjust the number of neighbors as needed\n",
    "\n",
    "# Impute missing values on normalized data\n",
    "imputed_data = imputer.fit_transform(normalized_df)\n",
    "\n",
    "# Convert the imputed data back to a DataFrame\n",
    "imputed_df = pd.DataFrame(imputed_data, columns=numeric_columns.columns, index=weatherAUS_df.index)\n",
    "\n",
    "# Inverse transform to get original scale\n",
    "imputed_original_scale = scaler.inverse_transform(imputed_df)\n",
    "\n",
    "# Update the original DataFrame with the imputed values\n",
    "weatherAUS_df[numeric_columns.columns] = imputed_original_scale\n",
    "\n",
    "# Verify if any missing values are remaining\n",
    "print(\"Number of missing values after imputation:\")\n",
    "print(weatherAUS_df.isnull().sum())\n",
    "\n",
    "print(weatherAUS_df.head())\n",
    "# Now weatherAUS_df contains imputed values for normalized numeric columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94b4376-bb98-43bf-b22d-586f98f2f475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Select numeric columns for normalization and imputation\n",
    "# numeric_columns = weatherAUS_df.select_dtypes(include=['number'])\n",
    "\n",
    "# # Initialize the StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # Normalize the numeric columns\n",
    "# normalized_data = scaler.fit_transform(numeric_columns)\n",
    "\n",
    "# # Convert the normalized data back to a DataFrame\n",
    "# normalized_df = pd.DataFrame(normalized_data, columns=numeric_columns.columns, index=weatherAUS_df.index)\n",
    "\n",
    "# # Calculate the mean values for each column\n",
    "# column_means = normalized_df.mean()\n",
    "\n",
    "# # Impute missing values with column-wise means\n",
    "# imputed_df = normalized_df.fillna(column_means)\n",
    "\n",
    "# # Inverse transform to get original scale\n",
    "# imputed_original_scale = scaler.inverse_transform(imputed_df)\n",
    "\n",
    "# # Convert the imputed data back to a DataFrame\n",
    "# imputed_original_scale_df = pd.DataFrame(imputed_original_scale, columns=numeric_columns.columns, index=weatherAUS_df.index)\n",
    "\n",
    "# # Update the original DataFrame with the imputed values\n",
    "# weatherAUS_df[numeric_columns.columns] = imputed_original_scale_df\n",
    "\n",
    "# # Verify if any missing values are remaining\n",
    "# print(\"Number of missing values after imputation:\")\n",
    "# print(weatherAUS_df.isnull().sum())\n",
    "\n",
    "# print(weatherAUS_df.head())\n",
    "# # Now weatherAUS_df contains imputed values for normalized numeric columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b16cc4-91a5-4feb-a317-9bcd337524ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Define the imputer with 'most_frequent' strategy\n",
    "mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "count_na_rows = weatherAUS_df.isna().any(axis=1).sum()\n",
    "\n",
    "print(\"Number of rows with at least one NaN value:\", count_na_rows)\n",
    "# Select categorical columns\n",
    "categorical_columns = weatherAUS_df.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "# Impute missing values in categorical columns\n",
    "weatherAUS_df[categorical_columns] = mode_imputer.fit_transform(weatherAUS_df[categorical_columns])\n",
    "\n",
    "print(weatherAUS_df.isna().sum())\n",
    "\n",
    "\n",
    "# Assuming weatherAUS_df is your DataFrame\n",
    "\n",
    "# Count rows with at least one NaN value\n",
    "count_na_rows = weatherAUS_df.isna().any(axis=1).sum()\n",
    "\n",
    "print(\"Number of rows with at least one NaN value:\", count_na_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03f9187-0166-4933-9a66-6f89b945d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Calculate z-scores for each numeric column\n",
    "z_scores = stats.zscore(weatherAUS_df.select_dtypes(include=np.number))\n",
    "\n",
    "# Create a DataFrame of z-scores\n",
    "z_scores_df = pd.DataFrame(z_scores, columns=weatherAUS_df.select_dtypes(include=np.number).columns)\n",
    "\n",
    "# Set up the boxplot figure\n",
    "plt.figure(figsize=(28, 6))\n",
    "\n",
    "# Draw boxplots for each numeric column\n",
    "sns.boxplot(data=z_scores_df, orient='v', palette='Set2')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Boxplot of Z-Scores for Numeric Columns')\n",
    "plt.xlabel('Z-Score')\n",
    "plt.ylabel('Numeric Columns')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "threshold = 3\n",
    "\n",
    "# Find rows with any z-score exceeding the threshold\n",
    "outlier_rows = weatherAUS_df[(abs_z_scores > threshold).any(axis=1)]\n",
    "\n",
    "# Print rows with outliers\n",
    "print(\"Rows with outliers:\")\n",
    "print(outlier_rows)\n",
    "\n",
    "# Replace outlier values with column-wise average\n",
    "for column in weatherAUS_df.select_dtypes(include=np.number).columns:\n",
    "    mean_value = weatherAUS_df[column].mean()\n",
    "    weatherAUS_df.loc[outlier_rows.index, column] = mean_value\n",
    "\n",
    "# Verify that the outliers have been replaced with the average values\n",
    "print(\"\\nUpdated DataFrame:\")\n",
    "print(weatherAUS_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375370a6-6aa2-4ff8-a1ca-a06681e7ebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.pylab as pylab\n",
    "# import seaborn as sns\n",
    "\n",
    "# weatherAUS_df_numeric = weatherAUS_df.select_dtypes(include=['number'])\n",
    "# params = {\n",
    "#     'legend.fontsize': 'x-large',\n",
    "#     'figure.figsize': (15, 5),\n",
    "#     'axes.labelsize': 'x-large',\n",
    "#     'axes.titlesize':'x-large',\n",
    "#     'xtick.labelsize':'x-large',\n",
    "#     'ytick.labelsize':'x-large'\n",
    "# }\n",
    "# pylab.rcParams.update(params)\n",
    "\n",
    "# plt.figure(figsize=(32, 62))\n",
    "\n",
    "# num_cols = 3\n",
    "# num_rows = int(weatherAUS_df_numeric.shape[1] / num_cols) + 1\n",
    "\n",
    "# for index, col in enumerate(weatherAUS_df_numeric.drop('RainTomorrow', axis=1).columns):\n",
    "#     plt.subplot(num_rows, num_cols, index + 1)\n",
    "#     sns.histplot(weatherAUS_df_numeric, x=col, hue='RainTomorrow', kde=True, bins=50)\n",
    "\n",
    "#     # Increase x-axis and y-axis title font size\n",
    "#     plt.xlabel(col, fontsize=20)\n",
    "#     plt.ylabel('Count', fontsize=20)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb00bf0c-fea1-4108-983f-d57fc6439b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "weatherAUS_df_numeric = weatherAUS_df.select_dtypes(include=['number'])\n",
    "attributes = weatherAUS_df_numeric.columns.tolist()\n",
    "\n",
    "scatter_matrix(weatherAUS_df_numeric[attributes], figsize=(32, 72))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fde7cfd-918d-4d61-81c8-c88990cf42ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# plt.figure(figsize=(32, 32))\n",
    "\n",
    "# num_cols = 5\n",
    "# num_rows = int(weatherAUS_df_numeric.shape[1] / num_cols) + 1\n",
    "\n",
    "# for index, col in enumerate(weatherAUS_df_numeric.drop('RainTomorrow', axis=1).columns):\n",
    "#     plt.subplot(num_rows, num_cols, index + 1)\n",
    "#     sns.scatterplot(data=weatherAUS_df_numeric, x=col, y='RainTomorrow')\n",
    "\n",
    "#     # Increase x-axis and y-axis title font size\n",
    "#     plt.xlabel(col, fontsize=20)\n",
    "#     plt.ylabel('RainTomorrow', fontsize=20)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3113d4-bbcc-436d-9f94-73fc8f7102a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weatherAUS_df.drop(columns=['Cloud9am', 'Cloud3pm'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc60cfe-468c-497a-9c42-92f974df4a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weatherAUS_df_corr_matrix = weatherAUS_df.corr(numeric_only=True)\n",
    "# print(weatherAUS_df_corr_matrix['RainTomorrow'])\n",
    "# fig, ax = plt.subplots(figsize=(20, 10))\n",
    "# sns.heatmap(weatherAUS_df.corr(numeric_only=True), cmap='RdBu', annot=True, fmt=\".2f\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba16bf67-6c6c-46f1-9c79-dd109483efc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.impute import SimpleImputer\n",
    "\n",
    "# # Define the imputer with 'most_frequent' strategy\n",
    "# mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# # Select categorical columns\n",
    "# categorical_columns = weatherAUS_df.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "# # Impute missing values in categorical columns\n",
    "# weatherAUS_df[categorical_columns] = mode_imputer.fit_transform(weatherAUS_df[categorical_columns])\n",
    "\n",
    "\n",
    "# # Now weatherAUS_df contains imputed values for categorical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a5c3da-67e1-412e-9633-b283722a714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# # Define numeric and categorical columns\n",
    "# numeric_columns = weatherAUS_df.select_dtypes(include=['number']).columns\n",
    "# categorical_columns = weatherAUS_df.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "# # Define the transformer for numeric columns (no imputation needed)\n",
    "# numeric_transformer = SimpleImputer(strategy='constant')  # Use 'constant' to keep numeric values as they are\n",
    "\n",
    "# # Define the transformer for categorical columns (impute with mode)\n",
    "# categorical_transformer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# # Combine the transformers using ColumnTransformer\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', numeric_transformer, numeric_columns),\n",
    "#         ('cat', categorical_transformer, categorical_columns)\n",
    "#     ])\n",
    "\n",
    "# # Apply the transformation to the data\n",
    "# transformed_data = preprocessor.fit_transform(weatherAUS_df)\n",
    "\n",
    "# # Convert the transformed data back to a DataFrame\n",
    "# transformed_df = pd.DataFrame(transformed_data, columns=numeric_columns.append(categorical_columns))\n",
    "\n",
    "# # Verify if any missing values are remaining\n",
    "# print(\"Number of missing values after imputation:\")\n",
    "# print(transformed_df.isnull().sum())\n",
    "# weatherAUS_df = transformed_df\n",
    "\n",
    "# # Now transformed_df contains imputed values for categorical columns and keeps numeric values unchanged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36db1732-9e8f-474f-a82f-b4ac222ab7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weatherAUS_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a36103-43ce-4c5f-9ab1-0bba3e0b2901",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60512cbd",
   "metadata": {},
   "source": [
    "# Question 2: Multi-Class Classification Using Logistic Regression\n",
    "<hr style=\"border:1px solid orange\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18669a33",
   "metadata": {},
   "source": [
    "#### Read the content of the `penguins.csv` file and perform the following:\n",
    "\n",
    "> **Q2.1.** Preprocess and clean the dataset (**Note:** Make sure to document your preprocessing step): This step should include the following:\n",
    "\n",
    "        - Dealing with the missing data\n",
    "        - Dealing with the irregular data (outliers)\n",
    "        - Dealing with the unnecessary data\n",
    "        - Dealing with the inconsistent data\n",
    "        - Encoding categorical data \n",
    "        \n",
    "> **Q2.2.** Visualize the dataset\n",
    "\n",
    "> **Q2.3.** Discuss the preliminary observations about the dataset. You may base your discussion on your visualizations, measures of central tendency, and measures of variability \n",
    "\n",
    "> **Q2.4.** Build a classification model using Logistic Regression to predict the penguins species.\n",
    "\n",
    "> **Q2.5.** Evaluate and discuss the model performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c01ebd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "??? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06c4859",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "# Part 2: Reflection\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f41c86",
   "metadata": {},
   "source": [
    "As a second stepâ€”after answering the questions, include the following:\n",
    "1. A reflection of your experience performing the activity. \n",
    "2. A reflection on the importance of learning this activity.\n",
    "\n",
    "**Note:** include your reflection in this notebook as markdown cells. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04ec951",
   "metadata": {},
   "source": [
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844c3dbe",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "# Submission\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd22e1a",
   "metadata": {},
   "source": [
    "Submit **Lab2.ipynb** to the **Lab 2 - Binary and Multi-class Classification Using Logistic Regression (Dropbox)** on D2L by the due date. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f053c344",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "# Grading Rubric\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c85704",
   "metadata": {},
   "source": [
    "| Criterion                                  | Excellent                                                   | Good                                                        | Average                                                    | Below Average                                               | Poor                                                        | No Attempt                                                 |\n",
    "|--------------------------------------------|-------------------------------------------------------------|-------------------------------------------------------------|------------------------------------------------------------|--------------------------------------------------------------|-------------------------------------------------------------|------------------------------------------------------------|\n",
    "| **Part 1:** Activity-Question 1.1           | **10 points** - Completes all aspects of the question correctly | **8 points** - Completes most aspects of the question correctly | **6 points** - Completes aspects of the question correctly, and some incorrectly | **4 points** - Completes most aspects of the question incorrectly or does not attempt many aspects | **2 points** - Minimal effort or completes a few aspects of the question or very few correctly | **0 points** - Did not complete the question                   |\n",
    "| **Part 1:** Activity-Question 1.2           | **10 points** - Completes all aspects of the question correctly | **8 points** - Completes most aspects of the question correctly | **6 points** - Completes aspects of the question correctly, and some incorrectly | **4 points** - Completes most aspects of the question incorrectly or does not attempt many aspects | **2 points** - Minimal effort or completes a few aspects of the question or very few correctly | **0 points** - Did not complete the question                   |\n",
    "| **Part 1:** Activity-Question 1.3           | **10 points** - Completes all aspects of the question correctly | **8 points** - Completes most aspects of the question correctly | **6 points** - Completes aspects of the question correctly, and some incorrectly | **4 points** - Completes most aspects of the question incorrectly or does not attempt many aspects | **2 points** - Minimal effort or completes a few aspects of the question or very few correctly | **0 points** - Did not complete the question                   |\n",
    "| **Part 1:** Activity-Question 1.4           | **10 points** - Completes all aspects of the question correctly | **8 points** - Completes most aspects of the question correctly | **6 points** - Completes aspects of the question correctly, and some incorrectly | **4 points** - Completes most aspects of the question incorrectly or does not attempt many aspects | **2 points** - Minimal effort or completes a few aspects of the question or very few correctly | **0 points** - Did not complete the question                   |\n",
    "| **Part 1:** Activity-Question 1.5           | **10 points** - Completes all aspects of the question correctly | **8 points** - Completes most aspects of the question correctly | **6 points** - Completes aspects of the question correctly, and some incorrectly | **4 points** - Completes most aspects of the question incorrectly or does not attempt many aspects | **2 points** - Minimal effort or completes a few aspects of the question or very few correctly | **0 points** - Did not complete the question                   |\n",
    "| **Part 1:** Activity-Question 2.1           | **10 points** - Completes all aspects of the question correctly | **8 points** - Completes most aspects of the question correctly | **6 points** - Completes aspects of the question correctly, and some incorrectly | **4 points** - Completes most aspects of the question incorrectly or does not attempt many aspects | **2 points** - Minimal effort or completes a few aspects of the question or very few correctly | **0 points** - Did not complete the question                   |\n",
    "| **Part 1:** Activity-Question 2.2           | **10 points** - Completes all aspects of the question correctly | **8 points** - Completes most aspects of the question correctly | **6 points** - Completes aspects of the question correctly, and some incorrectly | **4 points** - Completes most aspects of the question incorrectly or does not attempt many aspects | **2 points** - Minimal effort or completes a few aspects of the question or very few correctly | **0 points** - Did not complete the question                   |\n",
    "| **Part 1:** Activity-Question 2.3           | **10 points** - Completes all aspects of the question correctly | **8 points** - Completes most aspects of the question correctly | **6 points** - Completes aspects of the question correctly, and some incorrectly | **4 points** - Completes most aspects of the question incorrectly or does not attempt many aspects | **2 points** - Minimal effort or completes a few aspects of the question or very few correctly | **0 points** - Did not complete the question                   |\n",
    "| **Part 1:** Activity-Question 2.4           | **10 points** - Completes all aspects of the question correctly | **8 points** - Completes most aspects of the question correctly | **6 points** - Completes aspects of the question correctly, and some incorrectly | **4 points** - Completes most aspects of the question incorrectly or does not attempt many aspects | **2 points** - Minimal effort or completes a few aspects of the question or very few correctly | **0 points** - Did not complete the question                   |\n",
    "| **Part 1:** Activity-Question 2.5           | **10 points** - Completes all aspects of the question correctly | **8 points** - Completes most aspects of the question correctly | **6 points** - Completes aspects of the question correctly, and some incorrectly | **4 points** - Completes most aspects of the question incorrectly or does not attempt many aspects | **2 points** - Minimal effort or completes a few aspects of the question or very few correctly | **0 points** - Did not complete the question                   |\n",
    "| **Part 2:** Reflection                      | **10 points** - Reflection clearly ties to the module content; experience and importance clearly laid out | **8 points** - Reflection mostly ties to the module content; experience & importance are discussed | **6 points** - Reflection ties minimally to the module content; experience & importance are discussed but not thoroughly | **4 points** - Reflection does not tie to the module content; experience & importance are minimally discussed | **2 points** - Minimal effort to tie to content; minimal effort to describe experience/importance | **0 points** - Did not complete the reflection                 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26913da0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "214.052px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
